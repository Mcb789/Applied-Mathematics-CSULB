{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376a337c",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Macy Boren\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505a235",
   "metadata": {},
   "source": [
    "# __MATH323 &ndash; Introduction to Numerical Analysis &ndash; Fall 2023__\n",
    "\n",
    "# Programming Assignment 1 \n",
    "\n",
    "\n",
    "In this programming assignment, you will use your programming skills to compute approximations of different quantities and investigate their errors. This gives you the opportunity to assess your understanding at this point in the course. If you need help, please come and see me. I am here to support you! \n",
    "\n",
    "## Goals\n",
    "\n",
    "### By the end of this assignment you will have practiced several topics, including:\n",
    "\n",
    "1. the error, absolute error and relative error\n",
    "2. the impact of computer arithmetic \n",
    "3. the Taylor polynomial and its error\n",
    "4. the basics of programming in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1ad2c",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "You have three weeks to complete this programming assignment. You are required to use LaTeX and Python to answer the questions. The procedure to submit this assignment is available in the Jupyter notebook `slides_review_basics_programming` in Canvas and is mandatory. Note that no late assignment will be accepted. \n",
    "\n",
    "**This assignment is due at 3:00 p.m. Wednesday, Sep 20 on Canvas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea50a7",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "* Part 0: Preliminary (1 point)\n",
    "* Part 1: Stirling's approximation (8 points)\n",
    "    * Question 1 (4 points)\n",
    "    * Question 2 (3 points)\n",
    "    * Question 3 (1 point)\n",
    "* Part 2: Golden ratio (6 points)\n",
    "    * Question 1 (6 points)\n",
    "* Part 3: Estimations of $\\pi$ (7 points)\n",
    "    * Question 1 (3 points)\n",
    "    * Question 2 (4 points)\n",
    "* Part 4: Taylor polynomials (11 points)\n",
    "    * Question 1 (4 points)\n",
    "    * Question 2 (3 points)\n",
    "    * Question 3 (4 points)\n",
    "* Part 5: Approximations of the exponential function (9 points)\n",
    "    * Question 1 (1 point)\n",
    "    * Question 2 (2 points)\n",
    "    * Question 3 (6 points)\n",
    "* Part 6: Computation of a squence (13 points)\n",
    "    * Question 1 (2 points)\n",
    "    * Question 2 (2 points)\n",
    "    * Question 3 (2 points)\n",
    "    * Question 4 (2 points)\n",
    "    * Question 5 (5 points)\n",
    "\n",
    "Total points: **55**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ee822",
   "metadata": {},
   "source": [
    "## Part 0:  Preliminary (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37289616",
   "metadata": {},
   "source": [
    "**Question 1**: Import in the cell below all the modules that you will need in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d427c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt # library to display the results\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81da65d",
   "metadata": {},
   "source": [
    "## Part 1: Stirling's approximation (8 points)\n",
    "\n",
    "The Stirling's approximation \n",
    "\n",
    "\\begin{equation*}\n",
    "    s_n = \\frac{n^n\\sqrt{2\\pi n}}{e^n}\n",
    "\\end{equation*}\n",
    "\n",
    "estimates the factorial of $n$, that is $n! = 1\\times2\\times3\\times\\dots\\times n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758d6d8",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Compute the factorial of $n$ and its Stirling's approximation for $n=1,2,\\dots,12$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b8b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "fact_vec = np.zeros(12)\n",
    "stirling_vec = np.zeros(12)\n",
    "\n",
    "for a in range (1,13):\n",
    "    n = n * a\n",
    "    stir = ((a**a)* np.sqrt(2 * np.pi *a)) / (np.exp(a))\n",
    "    fact_vec[a-1] = n\n",
    "    stirling_vec[a-1] = stir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12b25e",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Compute the absolute error and relative error for each $n$ and display it as a table of three columns containing the values of $n$, the absolute errors and the relative errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84381b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n \t absolute error \t relative error \n",
      "\n",
      "1 \t 7.786e-02 \t\t 7.786e-02\n",
      "2 \t 8.100e-02 \t\t 4.050e-02\n",
      "3 \t 1.638e-01 \t\t 2.730e-02\n",
      "4 \t 4.938e-01 \t\t 2.058e-02\n",
      "5 \t 1.981e+00 \t\t 1.651e-02\n",
      "6 \t 9.922e+00 \t\t 1.378e-02\n",
      "7 \t 5.960e+01 \t\t 1.183e-02\n",
      "8 \t 4.176e+02 \t\t 1.036e-02\n",
      "9 \t 3.343e+03 \t\t 9.213e-03\n",
      "10 \t 3.010e+04 \t\t 8.296e-03\n",
      "11 \t 3.012e+05 \t\t 7.545e-03\n",
      "12 \t 3.314e+06 \t\t 6.919e-03\n"
     ]
    }
   ],
   "source": [
    "print(\"%s \\t %s \\t %s \\n\" % (\"n\", \"absolute error\", \"relative error\"))\n",
    "\n",
    "for a in range (1,13):\n",
    "    abserror = np.abs(fact_vec[a-1] - stirling_vec[a-1])\n",
    "    relerror = abserror / np.abs(fact_vec[a-1])\n",
    "    print(\"%d \\t %1.3e \\t\\t %1.3e\" % (a, abserror, relerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386c06d",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Is the Stirling's approximation more accurate as $n$ increases? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1f39f",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  The table provided displays the $n$ value which us used to caluctated the exact value and Stirling's approximation, as well as, the absolute errors and relative errors. $n$ ranges from 1 to 12 and is used to to calculate Stirling's approximation and the exact factorization value. The absolute error is found by taking the difference between the exact value and Stirlings approximated value while, the relative error places the error in reference of the problem. This is achieved by dividing the absolute error by the exact value.\n",
    "\n",
    "This table of values will help us to determine if Stirling's approximation becomes more accurate as $n$ increases. By analyzing the more accurate relative error, it is shown that as $n$ increases the relative error decreases. Becuase of the decreasing error, that means Stirling's approximation becomes more accurate with increasing $n$ values. A smaller error value demonstrates that the approximation is getting closer to the real number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a08cdc",
   "metadata": {},
   "source": [
    "## Part 2: Golden ratio (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70cfb6",
   "metadata": {},
   "source": [
    "The golden ratio $\\alpha = \\frac{1+\\sqrt{5}}{2}$ can be approximated by the ratio $\\frac{F_{n}}{F_{n-1}}$. Here $F_n$ is the $n$th number in the Fibonacci sequence\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        F_0 =&\\,\\, 0, \\quad F_1 =1, \\\\\n",
    "        F_n =&\\,\\, F_{n-1} + F_{n-2}, \\qquad n = 2, 3, 4, \\dots\n",
    "    \\end{aligned}\n",
    "    \\right.\n",
    "\\end{equation*}\n",
    "\n",
    "Knowing that \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\lim_{n\\to\\infty} \\frac{F_{n}}{F_{n-1}} = \\alpha,\n",
    "\\end{equation*}\n",
    "\n",
    "we should expect the ratio to be more accurate when $n$ increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397412e",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Determine the **smallest** value of $n$ for which the approximation of the golden ratio has at least 5 significant digits. Print the approximation, its relative error and the value of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352813cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 12\n",
      "Approximation = 1.6179775280898876\n",
      "Relative Error = 3.48946069117676e-05\n"
     ]
    }
   ],
   "source": [
    "F_n1 = 1 \n",
    "F_n = 0\n",
    "n = 1\n",
    "approx_alpha = 0\n",
    "exact_alpha = (1 + np.sqrt(5))/(2)\n",
    "\n",
    "while abs(exact_alpha - approx_alpha)/abs(exact_alpha) >= (5 * (10 ** -5)):\n",
    "    F_n2 = F_n1 + F_n\n",
    "    F_n = F_n1\n",
    "    F_n1 = F_n2\n",
    "    approx_alpha = F_n1 / F_n \n",
    "    n +=1 \n",
    "    rel_error =  abs(exact_alpha - approx_alpha)/abs(exact_alpha)\n",
    "    \n",
    "print('n =', n)\n",
    "print('Approximation =', approx_alpha)\n",
    "print('Relative Error =', rel_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff8f22",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Estimations of $\\pi$ (7 points)\n",
    "\n",
    "In this part, you will compute estimations of $\\pi$. Knowing that the perimeter of a circle of radius 0.5 is equal to $\\pi$, you could estimate its parameter and hence $\\pi$ by the constructing regular polygons within it. This leads to the following recursion relation\n",
    "\n",
    "\\begin{equation*}\n",
    "p_{k+1} = 2^k\\,\\sqrt{ 2\\Big(\\,1-\\sqrt{1-\\Big(\\tfrac{p_k}{2^k}\\Big)^2}\\,\\Big)} \n",
    "\\end{equation*}\n",
    "\n",
    "for $k\\geq2$ and where $p_k$ is the perimeter of a $2^k$-sides polygon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5268ea",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Knowing that $p_2=2\\sqrt{2}$, compute the approximation of $\\pi$ and its absolute error for $k = 2, 3, \\dots, 36$. Display the results as a table of three columns containing the values of $k$, the approximations and the absolute errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981dd419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k \t Approximations \t Absolute Errors \t\n",
      "2 \t 3.06147 \t\t 8.013e-02\n",
      "3 \t 3.12145 \t\t 2.015e-02\n",
      "4 \t 3.13655 \t\t 5.044e-03\n",
      "5 \t 3.14033 \t\t 1.261e-03\n",
      "6 \t 3.14128 \t\t 3.154e-04\n",
      "7 \t 3.14151 \t\t 7.885e-05\n",
      "8 \t 3.14157 \t\t 1.971e-05\n",
      "9 \t 3.14159 \t\t 4.928e-06\n",
      "10 \t 3.14159 \t\t 1.232e-06\n",
      "11 \t 3.14159 \t\t 3.080e-07\n",
      "12 \t 3.14159 \t\t 7.704e-08\n",
      "13 \t 3.14159 \t\t 2.013e-08\n",
      "14 \t 3.14159 \t\t 1.218e-09\n",
      "15 \t 3.14159 \t\t 8.269e-09\n",
      "16 \t 3.14159 \t\t 4.621e-08\n",
      "17 \t 3.14159 \t\t 2.573e-07\n",
      "18 \t 3.14159 \t\t 1.472e-06\n",
      "19 \t 3.14160 \t\t 3.900e-06\n",
      "20 \t 3.14160 \t\t 3.900e-06\n",
      "21 \t 3.14167 \t\t 8.161e-05\n",
      "22 \t 3.14183 \t\t 2.370e-04\n",
      "23 \t 3.14245 \t\t 8.586e-04\n",
      "24 \t 3.14245 \t\t 8.586e-04\n",
      "25 \t 3.16228 \t\t 2.069e-02\n",
      "26 \t 3.16228 \t\t 2.069e-02\n",
      "27 \t 3.46410 \t\t 3.225e-01\n",
      "28 \t 4.00000 \t\t 8.584e-01\n",
      "29 \t 0.00000 \t\t 3.142e+00\n",
      "30 \t 0.00000 \t\t 3.142e+00\n",
      "31 \t 0.00000 \t\t 3.142e+00\n",
      "32 \t 0.00000 \t\t 3.142e+00\n",
      "33 \t 0.00000 \t\t 3.142e+00\n",
      "34 \t 0.00000 \t\t 3.142e+00\n",
      "35 \t 0.00000 \t\t 3.142e+00\n",
      "36 \t 0.00000 \t\t 3.142e+00\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "p_k = 2 * np.sqrt(2)\n",
    "print(\"%s \\t %s \\t %s \\t\" % ('k','Approximations','Absolute Errors'))\n",
    "\n",
    "for k in range(2,37):\n",
    "    p_k_1 = (2 ** k) * np.sqrt(2 * (1 - np.sqrt(1- ((p_k/(2 ** k))** 2))))\n",
    "    p_k = p_k_1\n",
    "    absolute_error = np.abs(np.pi - p_k)\n",
    "    print(\"%d \\t %2.5f \\t\\t %1.3e\"%(k,p_k,absolute_error))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a3af5",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "For which $k$ the approximation is the most accurate? Describe the behavior of the absolute error and explain the results. Provide numerical evidences of your claim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0847c",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  Using this recursion relation, the information should be presetned in three columns of k, the approximation, and the exact value. Becuase k in increasing the approximation should be increasing as well with the absolute error increasing as it aprroaches $\\pi$ and decreasing as the approximation gets further from $\\pi$.\n",
    "\n",
    "The K values corresponds with the approximations from the function $p_k$, which is the perimeter of a $2^k$-sides polygon, and the absolute error, which is calculated from the exact value $\\pi$. The approximation increases the most between k values 1 to 3 then seems to continuously increase at a slower rate around 3.14. At k = 28 the approximation of $\\pi$ hits 4 then after that the approximation is 0 due to the nature of the approximation.\n",
    "\n",
    "The absolute errors follow the pattern of the approximation which increase and decrease consistently. The trend is that as the approximation starts and ends further away from $\\pi$, the absolute error will be greater at the beginning and end, while more accurate in the center when the approximation is closest. \n",
    "\n",
    "The approximation is closest to $\\pi$ at k = 14 due to it corresponding with the smallest error of $1.218^{-09}$. The absolute error is also decreasing until this point then increases after. \n",
    "\n",
    "To analyse the series and show that k increases so does the approximation, let's take a look at the first square root. $\\sqrt{1-\\Big(\\tfrac{p_k}{2^k}\\Big)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b43a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value under the square root\n",
      "0.6435942529055825\n",
      "0.9207383260311116\n",
      "0.9805970430337126\n",
      "0.995173077079758\n",
      "0.9987947298671258\n",
      "0.9996987733274502\n",
      "0.9999246990040245\n",
      "0.9999811751054127\n",
      "0.999995293798502\n",
      "0.9999988234510098\n",
      "0.9999997058628389\n",
      "0.9999999264657152\n",
      "0.999999981616429\n",
      "0.9999999954041073\n",
      "0.9999999988510269\n",
      "0.9999999997127567\n",
      "0.9999999999281891\n",
      "0.9999999999820472\n",
      "0.9999999999955118\n",
      "0.9999999999988779\n",
      "0.9999999999997194\n",
      "0.9999999999999298\n",
      "0.9999999999999825\n",
      "0.9999999999999956\n",
      "0.9999999999999989\n",
      "0.9999999999999997\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "p_k = 2 * np.sqrt(2)\n",
    "print(\"%s\" % ('Value under the square root'))\n",
    "\n",
    "for k in range(2,37):\n",
    "    p_k_1 = (2 ** k) * np.sqrt(2 * (1 - np.sqrt(1- ((p_k/(2 ** k))** 2))))\n",
    "    p_k = p_k_1 \n",
    "    under =  np.sqrt(1- ((p_k/(2 ** k))** 2))\n",
    "    print(under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873bf4a",
   "metadata": {},
   "source": [
    "This shows that becuase the series is baised on past values, it will always be increasing. We also see that there is a point at which, the value under the square root in one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2daab3",
   "metadata": {},
   "source": [
    "## Part 4: Taylor polynomials (11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5a216",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Compute the fourth-degree Taylor polynomial of $g(x)=\\ln(1+x)$ around $x_0 = 0$. Show the details of your computation. Identify clearly the Taylor polynomial and its error term. What is the order of the Taylor polynomial approximating $g(x)$ with $x>0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810af8ef",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  The formula for the Taylor Series polynomial is given by...\n",
    "\n",
    "\\begin{equation*}\n",
    "    P_n(x) = \\displaystyle\\sum_{k=0}^n \\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\n",
    "\\end{equation*}\n",
    "\n",
    "And our knowns are $x_0 = 0$ , $g(x) = \\ln(1+x)$\n",
    "\n",
    "\\begin{equation*}\n",
    "    P_4(x) = g(x_0) + g^{(1)}(x_0)h + \\frac{g^{(2)}(x_0)}{2} h^2 + \\frac{g^{(3)}(x_0)}{6} h^3 + \\frac{g^{(4)}(x_0)}{24} h^4         \n",
    "\\end{equation*}\n",
    "\n",
    "We need to find up to the fourth derivative of g(x).\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    g(x_0) = &\\,\\, ln(1+x_0)\\\\\n",
    "    g^{(1)}(x_0) = &\\,\\, (1+x_0)^{(-1)}\\\\\n",
    "    g^{(2)}(x_0) = &\\,\\, -(1+x_0)^{(-2)}\\\\\n",
    "    g^{(3)}(x_0) = &\\,\\, 2(1+x_0)^{(-3)}\\\\\n",
    "    g^{(4)}(x_0) = &\\,\\, -6(1+x_0)^{(-4)}\\\\\n",
    "    g^5{(5)}(x_0) = &\\,\\, 24(1+x_0)^{(-5)}\\\\\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "Evaluating the derivatives at x_0 = 0 and x = x_0 + h we obtain\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    P_4(x) = &\\,\\, ln(1+x_0) + \\frac{h}{(1+x_0)} - \\frac{h^2}{2(1+x_0)^2} + \\frac{2h^3}{6(1+x_0)^3} - \\frac{6h^4}{24(1+x_0)^4}\\\\\n",
    "    = &\\,\\, ln(1+x_0) + \\frac{h}{(1+x_0)} - \\frac{h^2}{2(1+x_0)^2} + \\frac{h^3}{3(1+x_0)^3} - \\frac{h^4}{4(1+x_0)^4}\\\\\n",
    "    = &\\,\\, ln(1) + {h} - \\frac{h^2}{2} + \\frac{h^3}{3} - \\frac{h^4}{4}\\\\\n",
    "    = &\\,\\, {h} - \\frac{h^2}{2} + \\frac{h^3}{3} - \\frac{h^4}{4}\\\\\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "Where the truncation error term included is\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "    R_n(h) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!}h^{n+1}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    R_4(h) = &\\,\\,\\frac{f^{(4+1)}(\\xi)}{(4+1)!}h^{4+1}\\\\\n",
    "    = &\\,\\,\\frac{f^{(5)}(\\xi)}{(5)!}h^{5} \\\\\n",
    "    = &\\,\\,\\frac{24}{120(1+\\xi)^5}h^{5} \\\\\n",
    "    = &\\,\\,\\frac{h^5}{5(1+\\xi)^5} \\\\   \n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce6aa6",
   "metadata": {},
   "source": [
    "In this case $\\xi$ lies between the interval $x_0=0$ and h and is maximaized at $\\xi$ = 0, so we need to upper bound the absolute error.\n",
    "\n",
    "\\begin{equation*}\n",
    "    |R_4(h)| \\leq \\max_{\\xi} |\\frac{1}{(1+\\xi)}| \\frac{h^5}{5} = \\frac{h^5}{5}\n",
    "\\end{equation*}\n",
    "\n",
    "Finally it is reveiled that the Taylor Polynomial $P_n$ and its error term $R_n$ is \n",
    "\n",
    "\\begin{equation*}\n",
    "    g(x) = {h} - \\frac{h^2}{2} + \\frac{h^3}{3} - \\frac{h^4}{4} + \\frac{h^5}{5} \n",
    "\\end{equation*}\n",
    "\n",
    "Showing that the Taylor polynomial $P_4(x)$ is a fifth-order approximation of $g(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fce6ca",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Using the Taylor expansion of $g(x)$, compute the two first terms of the Taylor expansion of \n",
    "\n",
    "\\begin{equation*}\n",
    "    f(x) = \\ln\\big(\\tfrac{1+x}{1-x}\\big)=\\ln(1+x)-\\ln(1-x)\n",
    "\\end{equation*}\n",
    "\n",
    "around $x_0=0$. Determine the degree of the resulting Taylor polynomial and its first error term. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba0877",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  \n",
    "\n",
    "The Taylor series polynomial $P_n$ for $f(x) = ln(1-x)$\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    P_n(x) = &\\,\\,f(x_0) + f^{(1)}(x_0)h + \\frac{f^{(2)}(x_0)}{2} h^2 + \\frac{f^{(3)}(x_0)}{6} h^3 + \\frac{f^{(4)}(x_0)}{24} h^4 + \\cdots \\\\\n",
    "    = &\\,\\ ln(1) - x - \\frac{h^2}{2} - \\frac{h^3}{3} - \\frac{h^4}{4} - \\cdots \\\\\n",
    "    = &\\,\\ - h - \\frac{h^2}{2} - \\frac{h^3}{3} - \\frac{h^4}{4} +\\cdots \n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f993cd",
   "metadata": {},
   "source": [
    "The Taylor series polynomial $P_n$ for $f(x) = ln(1+x)$ \n",
    "\n",
    "\\begin{equation*}\n",
    "    P_n(x) = {h} - \\frac{h^2}{2} + \\frac{h^3}{3} - \\frac{h^4}{4} + \\cdots \n",
    "\\end{equation*}\n",
    "\n",
    "Then that means the Taylor series polynomial $P_2$ for $f(x) = ln(1+x) - ln(1-x)$\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "    P_2(x) = &\\,\\,{h} - \\frac{h^2}{2}  + \\frac{h^3}{3} -(- h - \\frac{h^2}{2} - \\frac{h^3}{3})\\\\\n",
    "    = &\\,\\, {h} - \\frac{h^2}{2} +  \\frac{h^3}{3} + \\frac{h^2}{2}  + \\frac{h^3}{3}\\\\\n",
    "    = &\\,\\, 2h + \\frac{2h^3}{3}\n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171a08d",
   "metadata": {},
   "source": [
    "The truncation error is found to be\n",
    "\n",
    "\\begin{equation*}\n",
    "    R_2(h) = \\frac{2h^5}{5} \n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The degree of $P_n$ is 2 with a fifth-order approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa9c18",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Compute and print approximations of $\\ln(2)$ using $g(x)$ and $f(x)$, and their absolute errors. Why the approximation computed with $f(x)$ is more accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de369f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(x) approximation of ln(2): \t 5.833e-01\n",
      "\t\tabsolute error:\t 1.098e-01\n",
      "\n",
      "f(x) approximation of ln(2): \t 7.407e-01\n",
      "\t\tabsolute error:\t 4.759e-02\n"
     ]
    }
   ],
   "source": [
    "# Put your code here \n",
    "# to get ln(2)\n",
    "# If g(x) is an approximation for ln(1+x) so x = 1\n",
    "# If f(x) is an apporximation for ln(1+x) - ln(1-x) then x = 1/3\n",
    "\n",
    "x = 1\n",
    "g_x_approx = x - ((x**2)/2) + ((x**3)/3) - ((x**4)/4)\n",
    "abs_error_g_x = np.abs(np.log(2)-g_x_approx)\n",
    "\n",
    "z = 1/3\n",
    "f_x_approx = (2*z) + ((2*(z**2))/3) #+ ((2*(z**5))/(5))\n",
    "abs_error_f_x = np.abs(np.log(2)-f_x_approx)\n",
    "\n",
    "print(\"%s \\t %1.3e\" % (\"g(x) approximation of ln(2):\",g_x_approx))\n",
    "print(\"\\t\\t%s\\t %1.3e\\n\"%(\"absolute error:\",abs_error_g_x))\n",
    "print(\"%s \\t %1.3e\" % (\"f(x) approximation of ln(2):\",f_x_approx))\n",
    "print(\"\\t\\t%s\\t %1.3e\"%(\"absolute error:\",abs_error_f_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f693c6e",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> The approximation of $ln(2)$ using the functions $g(x)$ and $f(x)$ and 0.5833 and 0.7408 respectively. With $f(x)$ having a smaller absolute error of 0.04759 as the absolute error of $f(x)$ is 0.1098.\n",
    "\n",
    "The function $f(x)$ is a more accurate approximation of $ln(2)$ becuase of its lower absolute error and taylor series polynomial. The taylor series of $f(x) = \\ln\\big(\\tfrac{1+x}{1-x}\\big)=\\ln(1+x)-\\ln(1-x)$ has more terms that cancel which provides more terms with fewer calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d2343",
   "metadata": {},
   "source": [
    "## Part 5: Approximations of the exponential function (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533041a",
   "metadata": {},
   "source": [
    "The exponential function can be approximated by the rational function \n",
    "\n",
    "\\begin{equation}\n",
    "    r(x) = \\frac{x^2+6x+12}{x^2-6x+12}\n",
    "\\end{equation}\n",
    "\n",
    "around $x=0$. Here we want to approximate the order of the rational approximation $r(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a569e8",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Create a function called `rational_app` that computes the rational approximation $r(x)$. The input is a vector containing the values of $x$ and the output is a vector containing the rational approximations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ab1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "def rational_app(vec):\n",
    "    i = 0\n",
    "    r_x = np.zeros(len(vec))\n",
    "    for x in vec:\n",
    "        r_x[i] = (x**2 + 6*x +12)/(x**2 - 6*x + 12)\n",
    "        i += 1\n",
    "    return r_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b0a99",
   "metadata": {},
   "source": [
    "**Question 2** \n",
    "\n",
    "Compute the absolute error of $r(x)$ with $x=2^{-n}$ for $n=0,1,2,\\dots,8.$ Display the results as a table of three columns containing $n$, $r$ and the absolute errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd4cecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\tr\t\tabsolute errors\n",
      "0\t2.714286\t3.996e-03\n",
      "1\t1.648649\t7.262e-05\n",
      "2\t1.284024\t1.748e-06\n",
      "3\t1.133148\t4.807e-08\n",
      "4\t1.064494\t1.410e-09\n",
      "5\t1.031743\t4.271e-11\n",
      "6\t1.015748\t1.314e-12\n",
      "7\t1.007843\t4.086e-14\n",
      "8\t1.003914\t1.110e-15\n"
     ]
    }
   ],
   "source": [
    "print('n\\tr\\t\\tabsolute errors')\n",
    "x_vals = np.zeros(9)\n",
    "abs_err = np.zeros(9)\n",
    "for n in range(0,9):\n",
    "    x_vals[n] = 2 ** (-n)\n",
    "    \n",
    "r_x = rational_app(x_vals)\n",
    "\n",
    "for i in range(0,9):\n",
    "    abs_err[i] = np.abs(np.exp(x_vals[i])-r_x[i])\n",
    "    print('%d\\t%f\\t%1.3e'%(i,r_x[i],abs_err[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71198d64",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Plot the absolute error as a function of $x$ in a logarithmic scale. Estimate the order of the rational approximation $r(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5cba09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 0.5 ** np.arange(0,9,1)\n",
    "\n",
    "plt.loglog(x, abs_err, label=\"$P_n$\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
    "plt.loglog(x, x**5, label=\"$h^5$\", color=\"red\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"convergence plot\")\n",
    "plt.xlabel(\"$h$\")\n",
    "plt.ylabel(\"absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e36f1",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  The absolute error and h are plotted on the graph and follow an almost parallel linear path at a fifth-order approximation where n = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c4040",
   "metadata": {},
   "source": [
    "## Part 6: Computation of a sequence (13 points)\n",
    "\n",
    "We want to compute the sequence \n",
    "\n",
    "\\begin{equation}\n",
    "    I_n = \\int_0^1 \\frac{x^{n-1}}{10+x} dx\n",
    "\\end{equation}\n",
    "\n",
    "for $n=1,2,\\dots$ To do so, we use the recursion relation \n",
    "\n",
    "\\begin{equation}\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "        I_1 =&\\,\\, \\ln\\big(\\tfrac{11}{10}\\big),  \\\\\n",
    "        I_{n+1} =&\\,\\, \\frac{1}{n} - 10 I_n, \\qquad n = 1, 2, \\dots\n",
    "    \\end{aligned}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "We also know that the sequence $I_n$ should be decreasing and all its terms should be positive.\n",
    "\n",
    "We now want to investigate the impact of the computer arithmetic on the computation of the sequence $I_n$. We then perturbe the starting value $I_1$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95f6c0",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Create a function `compute_In` that computes the terms for $n=1,2,\\dots,20$. The input is the starting value $I_1$ and the output is a vector containing the terms $I_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f09dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "def compute_In(I_n):\n",
    "    I_vec = np.zeros(21)\n",
    "    I_vec[0] = I_n\n",
    "    for n in range(1,21):\n",
    "        In_1 = (1/n) - (10*I_n)\n",
    "        I_vec[n] = In_1\n",
    "        I_n = In_1\n",
    "    return(I_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec00fd4",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Compute the sequence with three different starting values \n",
    "\n",
    "\\begin{equation}\n",
    "    I_1^0 = 0.095 \\qquad\\quad I_1^1 = 0.09531017 \\qquad\\quad  I_1^2 = 0.09531017980432\n",
    "\\end{equation}\n",
    "\n",
    "Display the results as a table of four columns containing $n$ and the sequence for $I_n^0$, $I_n^1$ and $I_n^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ebbdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\tI_n_0\t\tI_n_1\t\tI_n_2\n",
      "1 \t 9.500000e-02 \t 9.531017e-02 \t 9.531018e-02\n",
      "2 \t 5.000000e-02 \t 4.689830e-02 \t 4.689820e-02\n",
      "3 \t -4.440892e-16 \t 3.101700e-02 \t 3.101798e-02\n",
      "4 \t 3.333333e-01 \t 2.316333e-02 \t 2.315353e-02\n",
      "5 \t -3.083333e+00 \t 1.836667e-02 \t 1.846471e-02\n",
      "6 \t 3.103333e+01 \t 1.633333e-02 \t 1.535290e-02\n",
      "7 \t -3.101667e+02 \t 3.333333e-03 \t 1.313765e-02\n",
      "8 \t 3.101810e+03 \t 1.095238e-01 \t 1.148061e-02\n",
      "9 \t -3.101797e+04 \t -9.702381e-01 \t 1.019390e-02\n",
      "10 \t 3.101798e+05 \t 9.813492e+00 \t 9.172069e-03\n",
      "11 \t -3.101798e+06 \t -9.803492e+01 \t 8.279309e-03\n",
      "12 \t 3.101798e+07 \t 9.804401e+02 \t 8.116002e-03\n",
      "13 \t -3.101798e+08 \t -9.804318e+03 \t 2.173318e-03\n",
      "14 \t 3.101798e+09 \t 9.804326e+04 \t 5.518989e-02\n",
      "15 \t -3.101798e+10 \t -9.804325e+05 \t -4.804704e-01\n",
      "16 \t 3.101798e+11 \t 9.804325e+06 \t 4.871370e+00\n",
      "17 \t -3.101798e+12 \t -9.804325e+07 \t -4.865120e+01\n",
      "18 \t 3.101798e+13 \t 9.804325e+08 \t 4.865709e+02\n",
      "19 \t -3.101798e+14 \t -9.804325e+09 \t -4.865653e+03\n",
      "20 \t 3.101798e+15 \t 9.804325e+10 \t 4.865658e+04\n"
     ]
    }
   ],
   "source": [
    "print('n\\tI_n_0\\t\\tI_n_1\\t\\tI_n_2')\n",
    "\n",
    "I_0 = compute_In(0.095)\n",
    "I_1 = compute_In(0.09531017)\n",
    "I_2 = compute_In(0.09531017980432)\n",
    "\n",
    "for n in range(0,20):\n",
    "    print(\"%d \\t %1.6e \\t %1.6e \\t %1.6e\"%((n+1),I_0[n],I_1[n],I_2[n]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5aa5c8",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Let us neglect the round-off error of the term $\\frac{1}{n}$, find an approximation of the absolute error of the form  $\\Delta I_{n+1} \\approx f(\\Delta I_n)$. Here $\\Delta I_n$ is the absolute error of the term $I_n$. Explain your development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251634d4",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  *Put your answer and explanation here*\n",
    "\n",
    "We can see that $\\Delta I_{n+1}$ becomes a recursion relation of the current term and the next term. For example, we see that $I_1 = f(I_0)$ and so on. This means we can characterize the propogation of the absolute error. The question then is, what is the function $f(x)$ and how to do find that. We know that $e = x - x^*$ and $f(x) = f(x* + e)$ which is the taylor series and truncation error.\n",
    "\n",
    "x = x* + error\n",
    "x* = x - error (SHOW HOW ERROR BEHAVIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab543525",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Using the approximation of the absolute error obtained in **Question 3**, estimate the absolute error of each term of the sequence for $I_n^0$, $I_n^1$ and $I_n^2$. \n",
    "\n",
    "Display the results as a table of four columns containing $n$ and the sequence for $\\Delta I_n^0$, $\\Delta I_n^1$ and $\\Delta I_n^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e06744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17fcaf",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Comment the results of **Question 2** and explain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28315f20",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font>  The table displays the n-values from 1 to 20 with three different starting points of the sequence. At $I_1^0$ the sequence alternated from positive to negative and its power is increasing making the value vastly large or small. $I_1^1$ is more accurate with the exponents beginning to decrease but also alternates positive and negative at n = 9. $I_1^2$ is the most accurate with the lowest starting value at  $I_1^2$ = 0.09531017980432$ and decreases until n = 14, which then the values begin to alternate as well.\n",
    "\n",
    "The sequence should be all decreasing with positive values which is not reflected by the data in the table. This is due to the calcuation error of the sequence or by manipulating the starting value. These factors effect the sequence which some error may occur. The sequence calls for a staring value of $log\\big(\\tfrac{11}{10}\\big)$ but, we tested the sequence with values that are all greater than $log\\big(\\tfrac{11}{10}\\big)$, with $I_1^0$ being the furthest and least accurate to $I_1^2$ being the closest and most accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa8f39",
   "metadata": {},
   "source": [
    "### Congratulations! It is done!\n",
    "\n",
    "Please submit your assignment on Canvas following the procedure described in the Jupyter notebook `slides_review_basics_programming`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
